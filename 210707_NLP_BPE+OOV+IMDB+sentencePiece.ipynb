{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210707_NLP_BPE+OOV+IMDB+sentencePiece.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXbxRgyb+eqNsHDAN5Lwmw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhapis97/Practice_AI/blob/main/210707_NLP_BPE%2BOOV%2BIMDB%2BsentencePiece.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAR8-6JZf9vx"
      },
      "source": [
        "## BPE Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GSrVf-7fuCz"
      },
      "source": [
        "import re, collections"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX7-Lhzzfvew"
      },
      "source": [
        "num_merges = 10    # BPE를 몇 회 수행할 것인지 정함"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aQjABrAfwmi"
      },
      "source": [
        "dictionary = {'l o w </w>': 5,\n",
        "              'l o w e r </w>': 2,\n",
        "              'n e w e s t </w>': 6,\n",
        "              'w i d e s t </w>': 3}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnJIWsnNgLXO"
      },
      "source": [
        "- n - gram\n",
        "- unigram\n",
        "- bigram\n",
        "- trigram\n",
        "  \n",
        "l o w e s t  \n",
        "\n",
        "unigram으로 잘린 결과?  \n",
        "l  \n",
        "o  \n",
        "w  \n",
        "e  \n",
        "s  \n",
        "t  \n",
        "  \n",
        "bigram으로 잘린 결과?  \n",
        "lo    \n",
        "we    \n",
        "st  \n",
        "  \n",
        "trigram으로 잘린 결과?\n",
        "low  \n",
        "est  \n",
        "  \n",
        "나는 밥을 먹었어 하지만 배가 고파.\n",
        "unigram  \n",
        "나는  \n",
        "밥을  \n",
        "먹었어  \n",
        "하지만  \n",
        "배가  \n",
        "고파  \n",
        "  \n",
        "bigram  \n",
        "나는 밥을  \n",
        "밥을 먹었어  \n",
        "먹었어 하지만  \n",
        "하지만 배가  \n",
        "배가 고파"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2GCTrzkf89X"
      },
      "source": [
        "# 가장 빈도수가 높은 유니그램의 쌍을 하나의 유니그램으로 통합하는 과정으로 num_merges회 반복\n",
        "def get_state(dictionary):\n",
        "  # 유니그램의 pair들의 빈도수를 카운트\n",
        "  pairs = collections.defaultdict(int)    # collections.defaultdict(딕셔너리 초기값 지정)\n",
        "  for word, freq in dictionary.items():\n",
        "    symbols = word.split()\n",
        "    for i in range(len(symbols)-1):\n",
        "      pairs[symbols[i], symbols[i+1]] += freq\n",
        "  print('현재 pair들의 빈도수:', dict(pairs))\n",
        "  return pairs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvlHKMTgh7WD"
      },
      "source": [
        "def merge_dictionary(pair, v_in):\n",
        "    v_out = {}\n",
        "    bigram = re.escape(' '.join(pair))\n",
        "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
        "    for word in v_in:\n",
        "        w_out = p.sub(''.join(pair), word)\n",
        "        v_out[w_out] = v_in[word]\n",
        "    return v_out"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_1J6kj8inQO",
        "outputId": "a5d65f81-eac2-40fc-d56d-732ee06d8a0c"
      },
      "source": [
        "bpe_codes = {}\n",
        "bpe_codes_reverse = {}\n",
        "for i in range(num_merges):\n",
        "  print(\">> Step {0}\".format(i+1))\n",
        "  pairs = get_state(dictionary)\n",
        "  best = max(pairs, key=pairs.get)\n",
        "  dictionary = merge_dictionary(best, dictionary)\n",
        "\n",
        "  bpe_codes[best] = i\n",
        "  bpe_codes_reverse[best[0] + best[1]] = best\n",
        "  \n",
        "\n",
        "  print('New merge: {}'.format(best))\n",
        "  print('dictionary: {}'.format(dictionary))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> Step 1\n",
            "현재 pair들의 빈도수: {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 8, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('e', 's'): 9, ('s', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'e'): 3}\n",
            "New merge: ('e', 's')\n",
            "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w es t </w>': 6, 'w i d es t </w>': 3}\n",
            ">> Step 2\n",
            "현재 pair들의 빈도수: {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'es'): 6, ('es', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'es'): 3}\n",
            "New merge: ('es', 't')\n",
            "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est </w>': 6, 'w i d est </w>': 3}\n",
            ">> Step 3\n",
            "현재 pair들의 빈도수: {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est'): 6, ('est', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est'): 3}\n",
            "New merge: ('est', '</w>')\n",
            "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 4\n",
            "현재 pair들의 빈도수: {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "New merge: ('l', 'o')\n",
            "dictionary: {'lo w </w>': 5, 'lo w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 5\n",
            "현재 pair들의 빈도수: {('lo', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "New merge: ('lo', 'w')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 6\n",
            "현재 pair들의 빈도수: {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "New merge: ('n', 'e')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'ne w est</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 7\n",
            "현재 pair들의 빈도수: {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('ne', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "New merge: ('ne', 'w')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'new est</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 8\n",
            "현재 pair들의 빈도수: {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('new', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "New merge: ('new', 'est</w>')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 9\n",
            "현재 pair들의 빈도수: {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "New merge: ('low', '</w>')\n",
            "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 10\n",
            "현재 pair들의 빈도수: {('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "New merge: ('w', 'i')\n",
            "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'wi d est</w>': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTUCFKa9i2ou",
        "outputId": "ba4a2c40-58a0-466e-c635-790c662b044c"
      },
      "source": [
        "print(bpe_codes)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{('e', 's'): 0, ('es', 't'): 1, ('est', '</w>'): 2, ('l', 'o'): 3, ('lo', 'w'): 4, ('n', 'e'): 5, ('ne', 'w'): 6, ('new', 'est</w>'): 7, ('low', '</w>'): 8, ('w', 'i'): 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7r93pssqrk0"
      },
      "source": [
        "## OOV에 대처하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6scIj0EPpkFK"
      },
      "source": [
        "def get_pairs(word):\n",
        "  pairs = set()\n",
        "  prev_char = word[0]\n",
        "  for char in word[1:]:\n",
        "    pairs.add((prev_char, char))\n",
        "    prev_char = char\n",
        "  return pairs"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USdcr1Xxq-KY"
      },
      "source": [
        "def encode(orig):\n",
        "  word = tuple(orig) + ('</w>',)\n",
        "  print(\"__word split into characters:__ <tt>{}<tt>\".format(word))\n",
        "\n",
        "  pairs = get_pairs(word)\n",
        "\n",
        "  if not pairs:\n",
        "    return orig\n",
        "  \n",
        "  iteration = 0\n",
        "  while True:\n",
        "    iteration += 1\n",
        "    print(\"__Iteration {}:__\".format(iteration))\n",
        "\n",
        "    print(\"Bigram in the word: {}\".format(pairs))\n",
        "    bigram = min(pairs, key = lambda pair: bpe_codes.get(pair, float('inf')))\n",
        "    print(\"candidate for merging: {}\".format(bigram))\n",
        "    if bigram not in bpe_codes:\n",
        "      print(\"__Candidate not in BPE merges, algorithm stops.__\")\n",
        "      break\n",
        "    first, second = bigram\n",
        "    new_word = []\n",
        "    i = 0\n",
        "    while i < len(word):\n",
        "      try:\n",
        "        j = word.index(first, i)\n",
        "        new_word.extend(word[i:j])\n",
        "        i = j\n",
        "      except:\n",
        "        new_word.extend(word[i:])\n",
        "        break\n",
        "\n",
        "      if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
        "        new_word.append(first+second)\n",
        "        i += 2\n",
        "      else:\n",
        "        new_word.append(word[i])\n",
        "        i += 1\n",
        "    new_word = tuple(new_word)\n",
        "    word = new_word\n",
        "    print(\"word after merging : {}\".format(word))\n",
        "    if len(word) == 1:\n",
        "      break\n",
        "    else:\n",
        "      pairs = get_pairs(word)\n",
        "  \n",
        "  # 특별토큰인 </w>는 출력하지 않는다.\n",
        "  if word[-1] == '</w>':\n",
        "    word = word[:-1]\n",
        "  elif word[-1].endswith('</w>'):\n",
        "    word = word[:-1] + (word[-1].replace('</w>', ''),)\n",
        "  return word"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LhZPNPjsp2J",
        "outputId": "992ae9a8-b421-4369-a747-5c5609f31138"
      },
      "source": [
        "orig = 'hi'\n",
        "word = tuple(orig) + ('</w>',)\n",
        "print(word)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('h', 'i', '</w>')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb9rpUOOtAZf",
        "outputId": "2833772b-98d6-4191-ede0-4b0c5bdd0c97"
      },
      "source": [
        "encode(\"lowest\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__word split into characters:__ <tt>('l', 'o', 'w', 'e', 's', 't', '</w>')<tt>\n",
            "__Iteration 1:__\n",
            "Bigram in the word: {('e', 's'), ('w', 'e'), ('l', 'o'), ('t', '</w>'), ('o', 'w'), ('s', 't')}\n",
            "candidate for merging: ('e', 's')\n",
            "word after merging : ('l', 'o', 'w', 'es', 't', '</w>')\n",
            "__Iteration 2:__\n",
            "Bigram in the word: {('w', 'es'), ('l', 'o'), ('t', '</w>'), ('es', 't'), ('o', 'w')}\n",
            "candidate for merging: ('es', 't')\n",
            "word after merging : ('l', 'o', 'w', 'est', '</w>')\n",
            "__Iteration 3:__\n",
            "Bigram in the word: {('o', 'w'), ('l', 'o'), ('est', '</w>'), ('w', 'est')}\n",
            "candidate for merging: ('est', '</w>')\n",
            "word after merging : ('l', 'o', 'w', 'est</w>')\n",
            "__Iteration 4:__\n",
            "Bigram in the word: {('o', 'w'), ('l', 'o'), ('w', 'est</w>')}\n",
            "candidate for merging: ('l', 'o')\n",
            "word after merging : ('lo', 'w', 'est</w>')\n",
            "__Iteration 5:__\n",
            "Bigram in the word: {('lo', 'w'), ('w', 'est</w>')}\n",
            "candidate for merging: ('lo', 'w')\n",
            "word after merging : ('low', 'est</w>')\n",
            "__Iteration 6:__\n",
            "Bigram in the word: {('low', 'est</w>')}\n",
            "candidate for merging: ('low', 'est</w>')\n",
            "__Candidate not in BPE merges, algorithm stops.__\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('low', 'est')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srKGotvst1s_",
        "outputId": "92cad758-6af2-4a9e-a928-df74ea1add43"
      },
      "source": [
        "encode('lowing')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__word split into characters:__ <tt>('l', 'o', 'w', 'i', 'n', 'g', '</w>')<tt>\n",
            "__Iteration 1:__\n",
            "Bigram in the word: {('l', 'o'), ('o', 'w'), ('n', 'g'), ('w', 'i'), ('g', '</w>'), ('i', 'n')}\n",
            "candidate for merging: ('l', 'o')\n",
            "word after merging : ('lo', 'w', 'i', 'n', 'g', '</w>')\n",
            "__Iteration 2:__\n",
            "Bigram in the word: {('lo', 'w'), ('n', 'g'), ('w', 'i'), ('g', '</w>'), ('i', 'n')}\n",
            "candidate for merging: ('lo', 'w')\n",
            "word after merging : ('low', 'i', 'n', 'g', '</w>')\n",
            "__Iteration 3:__\n",
            "Bigram in the word: {('low', 'i'), ('n', 'g'), ('g', '</w>'), ('i', 'n')}\n",
            "candidate for merging: ('low', 'i')\n",
            "__Candidate not in BPE merges, algorithm stops.__\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('low', 'i', 'n', 'g')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2D4ClOyuyH9",
        "outputId": "6e5ef055-d9bf-499c-aa22-cf8789f2499e"
      },
      "source": [
        "encode('highing')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__word split into characters:__ <tt>('h', 'i', 'g', 'h', 'i', 'n', 'g', '</w>')<tt>\n",
            "__Iteration 1:__\n",
            "Bigram in the word: {('i', 'g'), ('g', 'h'), ('h', 'i'), ('n', 'g'), ('g', '</w>'), ('i', 'n')}\n",
            "candidate for merging: ('i', 'g')\n",
            "__Candidate not in BPE merges, algorithm stops.__\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('h', 'i', 'g', 'h', 'i', 'n', 'g')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpCu3ouN2euf"
      },
      "source": [
        "## IMDB리뷰 토큰화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc7ZpEUQu-WA"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import urllib.request\n",
        "import pandas as pd"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skX0wnEX26YK",
        "outputId": "f6bd1e81-6316-4233-8fdc-2aba1e907fb8"
      },
      "source": [
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv', filename='IMDb_Reviews.csv')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x7f51b5f07d50>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZLeg4Z43L9O"
      },
      "source": [
        "train_df = pd.read_csv('IMDb_Reviews.csv')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "VXTQYDEz3W2Q",
        "outputId": "9011067f-0989-46f4-e8ce-2ebc604d84dd"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My family and I normally do not watch local mo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Believe it or not, this was at one time the wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>After some internet surfing, I found the \"Home...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>One of the most unheralded great works of anim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  My family and I normally do not watch local mo...          1\n",
              "1  Believe it or not, this was at one time the wo...          0\n",
              "2  After some internet surfing, I found the \"Home...          0\n",
              "3  One of the most unheralded great works of anim...          1\n",
              "4  It was the Sixties, and anyone with long hair ...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmKNZkq23YKM",
        "outputId": "fd49c96f-4767-4f35-87bb-5f8f910346e3"
      },
      "source": [
        "train_df['review']"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        My family and I normally do not watch local mo...\n",
              "1        Believe it or not, this was at one time the wo...\n",
              "2        After some internet surfing, I found the \"Home...\n",
              "3        One of the most unheralded great works of anim...\n",
              "4        It was the Sixties, and anyone with long hair ...\n",
              "                               ...                        \n",
              "49995    the people who came up with this are SICK AND ...\n",
              "49996    The script is so so laughable... this in turn,...\n",
              "49997    \"So there's this bride, you see, and she gets ...\n",
              "49998    Your mind will not be satisfied by this nobud...\n",
              "49999    The chaser's war on everything is a weekly sho...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl4qO5NN3v3E",
        "outputId": "075f5bfa-52bb-43fb-c07d-b4d8f3f3f390"
      },
      "source": [
        "train_df['sentiment']"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1\n",
              "1        0\n",
              "2        0\n",
              "3        1\n",
              "4        0\n",
              "        ..\n",
              "49995    0\n",
              "49996    0\n",
              "49997    0\n",
              "49998    0\n",
              "49999    1\n",
              "Name: sentiment, Length: 50000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62hE8FwS3xbV"
      },
      "source": [
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(train_df['review'], target_vocab_size=2**13)    # 토큰화(8192개 단어장 크기)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cfta4M8d4L5v",
        "outputId": "20edf88f-f182-4662-e5f8-a7d55b66cb3b"
      },
      "source": [
        "print(tokenizer.subwords[:100])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the_', ', ', '. ', 'a_', 'and_', 'of_', 'to_', 's_', 'is_', 'br', 'in_', 'I_', 'that_', 'this_', 'it_', ' /><', ' />', 'was_', 'The_', 't_', 'as_', 'with_', 'for_', '.<', 'on_', 'but_', 'movie_', 'are_', ' (', 'have_', 'his_', 'film_', 'not_', 'be_', 'you_', 'ing_', ' \"', 'ed_', 'it', 'd_', 'an_', 'at_', 'by_', 'he_', 'one_', 'who_', 'from_', 'y_', 'or_', 'e_', 'like_', 'all_', '\" ', 'they_', 'so_', 'just_', 'has_', ') ', 'about_', 'her_', 'out_', 'This_', 'some_', 'movie', 'ly_', 'film', 'very_', 'more_', 'It_', 'what_', 'would_', 'when_', 'if_', 'good_', 'up_', 'which_', 'their_', 'only_', 'even_', 'my_', 'really_', 'had_', 'can_', 'no_', 'were_', 'see_', '? ', 'she_', 'than_', '! ', 'there_', 'been_', 'get_', 'into_', 'will_', ' - ', 'much_', 'n_', 'because_', 'ing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReMuokdY56ej",
        "outputId": "2a9f9773-0087-4576-fe4e-9b0af35945d4"
      },
      "source": [
        "print(train_df['review'][20])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pretty bad PRC cheapie which I rarely bother to watch over again, and it's no wonder -- it's slow and creaky and dull as a butter knife. Mad doctor George Zucco is at it again, turning a dimwitted farmhand in overalls (Glenn Strange) into a wolf-man. Unfortunately, the makeup is virtually non-existent, consisting only of a beard and dimestore fangs for the most part. If it were not for Zucco and Strange's presence, along with the cute Anne Nagel, this would be completely unwatchable. Strange, who would go on to play Frankenstein's monster for Unuiversal in two years, does a Lenny impression from \"Of Mice and Men\", it seems.<br /><br />*1/2 (of Four)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW1JLc046Hy4",
        "outputId": "60b181eb-ef5d-4b92-adea-c56567d76dc2"
      },
      "source": [
        "# 인코딩\n",
        "print(\"토큰화된 샘플 질문: {}\".format(tokenizer.encode(train_df['review'][20])))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "토큰화된 샘플 질문: [1590, 4162, 132, 7107, 1892, 2983, 578, 76, 12, 4632, 3422, 7, 160, 175, 372, 2, 5, 39, 8051, 8, 84, 2652, 497, 39, 8051, 8, 1374, 5, 3461, 2012, 48, 5, 2263, 21, 4, 2992, 127, 4729, 711, 3, 1391, 8044, 3557, 1277, 8102, 2154, 5681, 9, 42, 15, 372, 2, 3773, 4, 3502, 2308, 467, 4890, 1503, 11, 3347, 1419, 8127, 29, 5539, 98, 6099, 58, 94, 4, 1388, 4230, 8057, 213, 3, 1966, 2, 1, 6700, 8044, 9, 7069, 716, 8057, 6600, 2, 4102, 36, 78, 6, 4, 1865, 40, 5, 3502, 1043, 1645, 8044, 1000, 1813, 23, 1, 105, 1128, 3, 156, 15, 85, 33, 23, 8102, 2154, 5681, 5, 6099, 8051, 8, 7271, 1055, 2, 534, 22, 1, 3046, 5214, 810, 634, 8120, 2, 14, 71, 34, 436, 3311, 5447, 783, 3, 6099, 2, 46, 71, 193, 25, 7, 428, 2274, 2260, 6487, 8051, 8, 2149, 23, 1138, 4117, 6023, 163, 11, 148, 735, 2, 164, 4, 5277, 921, 3395, 1262, 37, 639, 1349, 349, 5, 2460, 328, 15, 5349, 8127, 24, 10, 16, 10, 17, 8054, 8061, 8059, 8062, 29, 6, 6607, 8126, 8053]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tX_IeOY6ccO",
        "outputId": "83459c2a-68a4-4dde-8769-804197d24768"
      },
      "source": [
        "# 리뷰데이터가 아닌 샘플 문장으로 인코딩하고 디코딩해보자!!\n",
        "sample_string = \"It's mind-blowing to me that this film was even made.\"\n",
        "\n",
        "# 인코딩해서 저장\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "# 이를 다시 디코딩하자\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print('기존 문장: {}'.format(original_string))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 문장 [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 79, 681, 8058]\n",
            "기존 문장: It's mind-blowing to me that this film was even made.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM8p0jZA7McG",
        "outputId": "43d58f76-5ca5-45ad-f6e7-5f271b868608"
      },
      "source": [
        "print('단어 집합의 크기(Vocab size):', tokenizer.vocab_size)    # 2**13과 유사한 크기"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기(Vocab size): 8268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odj5dS9D7khY",
        "outputId": "ef9dd7e2-350b-4144-ebbe-bd7d97a7147f"
      },
      "source": [
        "for ts in tokenized_string:\n",
        "  print('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137 ----> It\n",
            "8051 ----> '\n",
            "8 ----> s \n",
            "910 ----> mind\n",
            "8057 ----> -\n",
            "2169 ----> blow\n",
            "36 ----> ing \n",
            "7 ----> to \n",
            "103 ----> me \n",
            "13 ----> that \n",
            "14 ----> this \n",
            "32 ----> film \n",
            "18 ----> was \n",
            "79 ----> even \n",
            "681 ----> made\n",
            "8058 ----> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEzMAdeC74cZ",
        "outputId": "85bf2ecc-8c27-4c40-bdaa-29ec5d1104bd"
      },
      "source": [
        "# 실험해보기\n",
        "# vocab 없어도 복원되는가?\n",
        "sample_string = \"It's mind-blowing to me that this film was evenxyz made.\"    # even -> evenxyz\n",
        "\n",
        "# 인코딩해서 저장\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "# 이를 다시 디코딩하자\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print('기존 문장: {}'.format(original_string))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 문장 [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 7974, 8132, 8133, 997, 681, 8058]\n",
            "기존 문장: It's mind-blowing to me that this film was evenxyz made.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyhIqsJe8ZQr",
        "outputId": "5c68145d-b0aa-4b3a-8cf7-78dbe3a1daf8"
      },
      "source": [
        "for ts in tokenized_string:\n",
        "  print('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137 ----> It\n",
            "8051 ----> '\n",
            "8 ----> s \n",
            "910 ----> mind\n",
            "8057 ----> -\n",
            "2169 ----> blow\n",
            "36 ----> ing \n",
            "7 ----> to \n",
            "103 ----> me \n",
            "13 ----> that \n",
            "14 ----> this \n",
            "32 ----> film \n",
            "18 ----> was \n",
            "7974 ----> even\n",
            "8132 ----> x\n",
            "8133 ----> y\n",
            "997 ----> z \n",
            "681 ----> made\n",
            "8058 ----> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KitCkJO-8hmW"
      },
      "source": [
        "# xyz가 x, y, z로 모두 나누어져 있음"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrH8suJA9oTQ"
      },
      "source": [
        "## IMDB리뷰 sentencePiece로 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vrDpZc580Lh",
        "outputId": "cf1139e8-a161-491b-a464-224f739bd71c"
      },
      "source": [
        "pip install sentencepiece"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 16.2MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 21.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 26.3MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 28.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 30.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 32.4MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 28.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 27.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92kB 28.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 29.2MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 29.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 29.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 29.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 29.2MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 29.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163kB 29.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 29.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 307kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890kB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931kB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0MB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1MB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1MB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 29.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 29.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 29.2MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYpDpPUvBsIN"
      },
      "source": [
        "import sentencepiece as spm\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import csv"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W94H3-QwCDZS"
      },
      "source": [
        "train_df = pd.read_csv('IMDb_Reviews.csv')"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "eHGrs8imCHJ1",
        "outputId": "fc2d52f1-cfa5-492a-f2f8-5c7dfd97a6bc"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My family and I normally do not watch local mo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Believe it or not, this was at one time the wo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>After some internet surfing, I found the \"Home...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>One of the most unheralded great works of anim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  My family and I normally do not watch local mo...          1\n",
              "1  Believe it or not, this was at one time the wo...          0\n",
              "2  After some internet surfing, I found the \"Home...          0\n",
              "3  One of the most unheralded great works of anim...          1\n",
              "4  It was the Sixties, and anyone with long hair ...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsKBhXDbCJ5y",
        "outputId": "6a30fe72-79b2-4c18-cdc0-2e23bbc4a24c"
      },
      "source": [
        "train_df['review']"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        My family and I normally do not watch local mo...\n",
              "1        Believe it or not, this was at one time the wo...\n",
              "2        After some internet surfing, I found the \"Home...\n",
              "3        One of the most unheralded great works of anim...\n",
              "4        It was the Sixties, and anyone with long hair ...\n",
              "                               ...                        \n",
              "49995    the people who came up with this are SICK AND ...\n",
              "49996    The script is so so laughable... this in turn,...\n",
              "49997    \"So there's this bride, you see, and she gets ...\n",
              "49998    Your mind will not be satisfied by this nobud...\n",
              "49999    The chaser's war on everything is a weekly sho...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HS7duzqCQj_",
        "outputId": "83666668-0ca2-4fb9-f353-67b428d9ce16"
      },
      "source": [
        "print('리뷰 개수:', len(train_df))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰 개수: 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp0AGGOfCVWl"
      },
      "source": [
        "with open('imdb_review.txt', 'w', encoding='utf-8') as f:\n",
        "  f.write('\\n'.join(train_df['review']))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqsRGnHqCjTS"
      },
      "source": [
        "spm.SentencePieceTrainer.Train('--input=imdb_review.txt --model_prefix=imdb --vocab_size=5000 --model_type=bpe --max_sentence_length=9999')"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GJp6Li0DVqL"
      },
      "source": [
        "- input: 학습시킬 파일\n",
        "- model_prefix: 만들어질 모델 이름\n",
        "- vocab_size: 단어집합크기\n",
        "- model_type: 사용할 모델(unigram(default), bpe, char, word)\n",
        "- pad_id, pad_piece: pad token id, 값\n",
        "- unk_id, unk_piece: unknown token id, 값\n",
        "- bos_id, bos_piece: begin of sentence token id, 값\n",
        "- eos_id, eos_piece: end of sequence token id, 값\n",
        "- user_defined_symbols: 사용자 정의 토큰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "e4WDNZRAC1BR",
        "outputId": "52a9d90a-fcc5-4fbb-d9d8-76b5d44d9631"
      },
      "source": [
        "vocab_list = pd.read_csv('imdb.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
        "vocab_list"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>▁t</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>▁a</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>8</td>\n",
              "      <td>-4992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>4</td>\n",
              "      <td>-4993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>7</td>\n",
              "      <td>-4994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>&amp;</td>\n",
              "      <td>-4995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>6</td>\n",
              "      <td>-4996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0     1\n",
              "0     <unk>     0\n",
              "1       <s>     0\n",
              "2      </s>     0\n",
              "3        ▁t     0\n",
              "4        ▁a    -1\n",
              "...     ...   ...\n",
              "4995      8 -4992\n",
              "4996      4 -4993\n",
              "4997      7 -4994\n",
              "4998      & -4995\n",
              "4999      6 -4996\n",
              "\n",
              "[5000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-OH47RlEZbA",
        "outputId": "dbe40ed8-9a12-444a-8f6e-56b35bc41c96"
      },
      "source": [
        "len(vocab_list)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk4MjAf_Eakw",
        "outputId": "693d220d-09d3-49ae-851e-5dd420d78ead"
      },
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "vocab_file = 'imdb.model'\n",
        "sp.load(vocab_file)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9z_U3hLEmxN",
        "outputId": "7ae4a06f-6dbf-42ff-b555-bcac3f689f0c"
      },
      "source": [
        "lines = [\n",
        "         \"I didn't at all think of it this way.\",\n",
        "         \"I have waited a long time for someone to film\"\n",
        "]\n",
        "for line in lines:\n",
        "  print(line)\n",
        "  print(sp.encode_as_pieces(line))    # 문장을 입력하면 서브워드 시퀀스로 변환\n",
        "  print(sp.encode_as_ids(line))       # 문장을 입력하면 정수 시퀀스로 변환\n",
        "  print()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I didn't at all think of it this way.\n",
            "['▁I', '▁didn', \"'\", 't', '▁at', '▁all', '▁think', '▁of', '▁it', '▁this', '▁way', '.']\n",
            "[41, 623, 4950, 4926, 138, 169, 378, 30, 58, 73, 413, 4945]\n",
            "\n",
            "I have waited a long time for someone to film\n",
            "['▁I', '▁have', '▁wa', 'ited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film']\n",
            "[41, 141, 1364, 1120, 4, 666, 285, 92, 1078, 33, 91]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1jDladcFCE7",
        "outputId": "a0a8dc89-147a-4d6f-e1c8-e56c6232a2ac"
      },
      "source": [
        "sp.GetPieceSize()    # 단어 집합의 크기"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NxCmDdKmFKB2",
        "outputId": "c9b6821f-20c6-4608-b6a4-00f4be8a8101"
      },
      "source": [
        "sp.IdToPiece(430)    # 정수로부터 매핑되는 서브워드 변환"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'▁character'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoFyuYujFMOQ",
        "outputId": "91299982-faeb-4f64-b4b0-d12e556e8aa4"
      },
      "source": [
        "sp.PieceToId('_character')   # 서브워드로부터 매핑되는 정수로 변환"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_2hNjVcUFUHt",
        "outputId": "a46d5221-0a42-4349-c579-a0cadd8dbbc2"
      },
      "source": [
        "sp.DecodeIds([41,141,1364,1120,4,666,285,92,1078,33,91])    # 정수 시퀀스로부터 문장으로 변환"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I have waited a long time for someone to film'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-7V3E9HaFkqd",
        "outputId": "21a27a45-1455-4e12-9e02-26c644c8c41b"
      },
      "source": [
        "# 서브워드 시퀀스로부터 문장으로 변환\n",
        "sp.DecodePieces(['▁I', '▁have', '▁wa', 'ited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film'])    # 언더바 아님 주의"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I have waited a long time for someone to film'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKximUsoF8pA",
        "outputId": "a623a889-328d-41e0-d739-ddd7b2d2fcf1"
      },
      "source": [
        "# encode -> 문장으로부터 인자값에 따라서 정수 시퀀스 또는 서브워드 시퀀스로 변환 가능\n",
        "print(sp.encode('I have waited a long time for someone to film', out_type=str))\n",
        "print(sp.encode('I have waited a long time for someone to film', out_type=int))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁I', '▁have', '▁wa', 'ited', '▁a', '▁long', '▁time', '▁for', '▁someone', '▁to', '▁film']\n",
            "[41, 141, 1364, 1120, 4, 666, 285, 92, 1078, 33, 91]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k24QVYoNGiwu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}